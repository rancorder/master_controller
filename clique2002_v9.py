#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
clique2002_monitor_v10.py - Image Hash Change Detector

â˜…ã‚³ãƒ³ã‚»ãƒ—ãƒˆ:
ã€Œç”»åƒã®ä¸­èº«ã€ã‚’OCRã§èª­ã‚€ã®ã‚’ã‚„ã‚ã€ã€Œç”»åƒã®æŒ‡ç´‹ï¼ˆãƒãƒƒã‚·ãƒ¥å€¤ï¼‰ã€ãŒå¤‰ã‚ã£ãŸã‹ã‚’ç›£è¦–ã™ã‚‹ã€‚
Sold-outã«ãªã‚‹ã¨ç”»åƒãŒå·®ã—æ›¿ã‚ã‚‹ã€ã¾ãŸã¯åŠ å·¥ã•ã‚Œã‚‹ã‚µã‚¤ãƒˆã®ç‰¹æ€§ã‚’åˆ©ç”¨ã™ã‚‹ã€‚

ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒª:
pip install requests beautifulsoup4
"""

import json
import logging
import os
import re
import sys
import time
import hashlib
from dataclasses import dataclass, asdict
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional
from urllib.parse import urljoin

import requests
from bs4 import BeautifulSoup

# ============================================================================
# è¨­å®š
# ============================================================================

@dataclass(frozen=True)
class Config:
    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
    BASE_URL: str = "http://www.clique2002.com/"
    TARGET_URL: str = "http://www.clique2002.com/goods-20-used.html"
    
    # é€šçŸ¥è¨­å®š
    CHATWORK_TOKEN: str = os.getenv('CHATWORK_TOKEN', '')
    CHATWORK_ROOM_ID: str = "385402385"
    
    # ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«
    STATE_FILE: Path = Path("clique2002_hash_state.json")
    
    # ãƒ­ã‚°è¨­å®š
    LOG_LEVEL: int = logging.INFO

# ============================================================================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# ============================================================================

def setup_logger(name: str) -> logging.Logger:
    logger = logging.getLogger(name)
    if not logger.handlers:
        handler = logging.StreamHandler(sys.stdout)
        formatter = logging.Formatter('%(asctime)s [%(levelname)s] %(message)s', datefmt='%H:%M:%S')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        logger.setLevel(Config.LOG_LEVEL)
    return logger

LOGGER = setup_logger('HashBot')

# ============================================================================
# ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«
# ============================================================================

@dataclass
class Product:
    product_id: str
    url: str
    image_url: str
    image_hash: str = ""  # ç”»åƒã®MD5å€¤
    
    def to_dict(self) -> dict:
        return asdict(self)

# ============================================================================
# ã‚³ã‚¢ãƒ­ã‚¸ãƒƒã‚¯: çŠ¶æ…‹ç®¡ç† & ãƒãƒƒã‚·ãƒ¥æ¯”è¼ƒ
# ============================================================================

class StateManager:
    """å‰å›ã®çŠ¶æ…‹ï¼ˆé †ä½ã¨ç”»åƒãƒãƒƒã‚·ãƒ¥ï¼‰ã‚’ç®¡ç†ã™ã‚‹"""
    
    def __init__(self, file_path: Path):
        self.file_path = file_path

    def load_previous_state(self) -> Dict[str, dict]:
        """
        å‰å›ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã€å‰å›å®Ÿè¡Œæ™‚ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚‚ä¿æŒã™ã‚‹ã€‚
        Return: {product_id: {'rank': int, 'hash': str}, 'metadata': {'timestamp': str}}
        """
        if not self.file_path.exists():
            return {}
        try:
            with open(self.file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                
            products_state = {
                p['product_id']: {'rank': i, 'hash': p.get('image_hash', '')}
                for i, p in enumerate(data.get('products', []))
            }
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’è¿½åŠ 
            products_state['metadata'] = {'timestamp': data.get('timestamp')}
            return products_state
        except Exception as e:
            LOGGER.error(f"âš ï¸ çŠ¶æ…‹ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")
            return {}

    def save_state(self, products: List['Product']): # 'Product'ã¯å‹ãƒ’ãƒ³ãƒˆã®ãŸã‚
        """ç¾åœ¨ã®çŠ¶æ…‹ã¨å®Ÿè¡Œã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ä¿å­˜"""
        current_time = datetime.now().isoformat()
        data = {
            'timestamp': current_time, # ã“ã“ã§æœ€æ–°ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ä¿å­˜
            'count': len(products),
            'products': [p.to_dict() for p in products]
        }
        try:
            with open(self.file_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            LOGGER.info(f"ğŸ’¾ çŠ¶æ…‹ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {len(products)}ä»¶")
        except Exception as e:
            LOGGER.error(f"âŒ ä¿å­˜å¤±æ•—: {e}")

# ============================================================================
# ã‚µãƒ¼ãƒ“ã‚¹: ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ & ãƒãƒƒã‚·ãƒ¥è¨ˆç®—
# ============================================================================

class HashScraper:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/120.0.0.0'
        })

    def get_image_hash(self, img_url: str) -> str:
        """ç”»åƒURLã‹ã‚‰ãƒã‚¤ãƒŠãƒªã‚’å–å¾—ã—MD5ãƒãƒƒã‚·ãƒ¥ã‚’è¿”ã™"""
        if not img_url:
            return "no_image"
        
        try:
            # ç”»åƒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆçŸ­ã‚ï¼‰
            resp = self.session.get(img_url, timeout=10)
            if resp.status_code == 200:
                return hashlib.md5(resp.content).hexdigest()
            return "download_error"
        except Exception:
            return "download_error"

    def scrape(self) -> List[Product]:
        """ã‚µã‚¤ãƒˆã‹ã‚‰å•†å“ãƒªã‚¹ãƒˆã¨ç”»åƒæƒ…å ±ã‚’å–å¾—"""
        LOGGER.info(f"ğŸ“¥ ã‚µã‚¤ãƒˆå–å¾—é–‹å§‹: {Config.TARGET_URL}")
        try:
            resp = self.session.get(Config.TARGET_URL, timeout=20)
            resp.raise_for_status()
        except Exception as e:
            LOGGER.error(f"âŒ æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
            return []

        soup = BeautifulSoup(resp.content, 'html.parser')
        products = []
        
        # å•†å“ãƒªãƒ³ã‚¯ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
        links = soup.find_all('a', href=re.compile(r'ct-([A-Z]{2}-\d{3})\.html', re.IGNORECASE))
        
        LOGGER.info(f"ğŸ” ç™ºè¦‹å•†å“æ•°: {len(links)}")

        for link in links:
            href = link.get('href')
            match = re.search(r'ct-([A-Z]{2}-\d{3})\.html', href, re.IGNORECASE)
            if not match:
                continue
                
            pid = match.group(1)
            detail_url = urljoin(Config.BASE_URL, href)
            
            # ç”»åƒURLã®ç‰¹å®š (ãƒªã‚¹ãƒˆãƒšãƒ¼ã‚¸ã®ã‚µãƒ ãƒã‚¤ãƒ«ã€ã¾ãŸã¯ãƒœã‚¿ãƒ³ç”»åƒã‚’æƒ³å®š)
            # â€»ã‚µã‚¤ãƒˆæ§‹é€ ã«åˆã‚ã›ã¦èª¿æ•´: ã“ã“ã§ã¯è¡Œ(tr)å†…ã®imgã‚¿ã‚°ã‚’æ¢ã™
            img_url = ""
            parent_tr = link.find_parent('tr')
            if parent_tr:
                # å•†å“ç”»åƒã£ã½ã„ã‚‚ã®ã‚’æ¢ã™ï¼ˆIDãŒå«ã¾ã‚Œã‚‹jpgãªã©ï¼‰
                img = parent_tr.find('img', src=re.compile(r'\.jpg|\.gif', re.IGNORECASE))
                if img:
                    img_url = urljoin(Config.BASE_URL, img.get('src', ''))

            products.append(Product(
                product_id=pid,
                url=detail_url,
                image_url=img_url
            ))
            
        return products

# ============================================================================
# é€šçŸ¥ã‚µãƒ¼ãƒ“ã‚¹
# ============================================================================

def send_chatwork(messages: List[str]):
    """Chatworké€šçŸ¥"""
    if not messages or not Config.CHATWORK_TOKEN:
        if messages:
            print("\n".join(messages)) # ãƒˆãƒ¼ã‚¯ãƒ³ãŒãªã„å ´åˆã¯æ¨™æº–å‡ºåŠ›
        return

    body = "[info][title]Clique Monitor Report (Hash)[/title]" + "\n".join(messages) + "[/info]"
    url = f"https://api.chatwork.com/v2/rooms/{Config.CHATWORK_ROOM_ID}/messages"
    headers = {'X-ChatWorkToken': Config.CHATWORK_TOKEN}
    
    try:
        requests.post(url, headers=headers, data={'body': body}, timeout=5)
        LOGGER.info("ğŸ“¢ é€šçŸ¥é€ä¿¡å®Œäº†")
    except Exception as e:
        LOGGER.error(f"âŒ é€šçŸ¥å¤±æ•—: {e}")

# ============================================================================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# ============================================================================

def main():
    start_time = time.time()
    
    scraper = HashScraper()
    state_manager = StateManager(Config.STATE_FILE)
    
    # 1. å‰å›ã®çŠ¶æ…‹ãƒ­ãƒ¼ãƒ‰
    prev_state = state_manager.load_previous_state()
    prev_ids = list(prev_state.keys())
    
    # 2. ç¾åœ¨ã®ãƒªã‚¹ãƒˆå–å¾—
    current_products = scraper.scrape()
    if not current_products:
        return

    current_ids = [p.product_id for p in current_products]
    messages = []

    # 3. é †ä½å¤‰å‹•ã¨ç”»åƒå¤‰æ›´ã®ãƒã‚§ãƒƒã‚¯
    # ãƒªã‚¹ãƒˆã®ä¸Šä½ãŒå¤‰ã‚ã£ãŸã‹ï¼Ÿ
    if prev_ids and current_ids[:30] != prev_ids[:30]:
        messages.append(f"ğŸ”„ é †ä½å¤‰å‹•ã‚ã‚Š (Top 30): {prev_ids[:30]} -> {current_ids[:30]}")

    # æ–°ç€ãƒã‚§ãƒƒã‚¯
    new_items = set(current_ids) - set(prev_ids)
    if new_items:
        messages.append(f"âœ¨ æ–°ç€å•†å“: {', '.join(new_items)}")

    # ç”»åƒãƒãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯ï¼ˆé‡ã„å‡¦ç†ãªã®ã§ã€å¿…è¦ãªå•†å“ã ã‘å®Ÿæ–½ã™ã‚‹ã®ãŒå‰ã ãŒã€ä»Šå›ã¯å…¨ä»¶ã‚„ã‚‹ï¼‰
    # â€»å…¨ä»¶ã‚„ã£ã¦ã‚‚ç”»åƒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã ã‘ãªã‚‰æ—©ã„ãŒã€é »ç¹ã«å©ããªã‚‰ä¸Šä½20ä»¶ã«çµã‚‹ãªã©ã®èª¿æ•´ã‚‚å¯
    LOGGER.info("ğŸ“¸ ç”»åƒãƒãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯é–‹å§‹...")
    
    changes_detected = False
    
    for product in current_products:
        # æ–°ç€ ã¾ãŸã¯ æ—¢å­˜å•†å“ã®ç”»åƒå¤‰æ›´ã‚’ãƒã‚§ãƒƒã‚¯
        prev_data = prev_state.get(product.product_id)
        
        # ãƒãƒƒã‚·ãƒ¥è¨ˆç®—å®Ÿè¡Œ
        current_hash = scraper.get_image_hash(product.image_url)
        product.image_hash = current_hash
        
        if prev_data:
            prev_hash = prev_data['hash']
            # å‰å›ã®ãƒãƒƒã‚·ãƒ¥ãŒã‚ã‚Šã€ã‹ã¤ä»Šå›ã¨é•ã†å ´åˆ
            if prev_hash and prev_hash != "download_error" and prev_hash != current_hash:
                LOGGER.info(f"âš ï¸ ç”»åƒå¤‰æ›´æ¤œçŸ¥: {product.product_id}")
                messages.append(f"ğŸ¨ ç”»åƒå¤‰åŒ– (çŠ¶æ…‹å¤‰æ›´ã®å¯èƒ½æ€§): {product.product_id}\n{product.url}")
                changes_detected = True
        elif product.product_id in new_items:
            # æ–°ç€ã¯ãƒãƒƒã‚·ãƒ¥æ¯”è¼ƒã§ããªã„ã®ã§ã‚¹ãƒ«ãƒ¼ï¼ˆæ–°ç€é€šçŸ¥ã§ã‚«ãƒãƒ¼ï¼‰
            pass

    # 4. çŠ¶æ…‹ä¿å­˜
    state_manager.save_state(current_products)
    
    # 5. é€šçŸ¥
    if messages:
        LOGGER.info(f"ğŸ“¢ é€šçŸ¥å¯¾è±¡: {len(messages)}ä»¶")
        send_chatwork(messages)
    else:
        LOGGER.info("ğŸ’¤ å¤‰åŒ–ãªã—")

    elapsed = time.time() - start_time
    LOGGER.info(f"âœ… å®Œäº†: {elapsed:.2f}ç§’")

if __name__ == "__main__":
    main()